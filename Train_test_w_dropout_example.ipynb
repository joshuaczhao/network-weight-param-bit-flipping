{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.nn import Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR10 images are 3x32x32, 3-channel 32x32 images\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, train_drop1, train_drop2, train_drop3, train_drop4, train_drop5):    \n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 12, 3, padding=1)   # (in-channels, out-channels, kernel size)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout1 = nn.Dropout(train_drop1)\n",
    "        self.conv2 = nn.Conv2d(12, 32, 3, padding=1)\n",
    "        self.dropout2 = nn.Dropout(train_drop2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.dropout3 = nn.Dropout(train_drop3)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 128)\n",
    "        self.dropout4 = nn.Dropout(train_drop4)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.dropout5 = nn.Dropout(train_drop5)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x, bool, drop1, drop2, drop3, drop4, drop5):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.dropout1(x)        \n",
    "        x = F.dropout(x, drop1, bool)\n",
    "\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.dropout(x, drop2, bool)\n",
    "        \n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.reshape(-1, 64 * 4 * 4)\n",
    "        x = self.dropout3(x)\n",
    "        x = F.dropout(x, drop3, bool)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout4(x)\n",
    "        x = F.dropout(x, drop4, bool)\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout5(x)\n",
    "        x = F.dropout(x, drop5, bool)\n",
    "    \n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create network instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(train_drop1=0, train_drop2=0, train_drop3=0, train_drop4=0, train_drop5=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer + Loss (Used Adam weight_decay param as L2 regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop without dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "[1,  2000] loss: 1.844\n",
      "[1,  4000] loss: 1.525\n",
      "[1,  6000] loss: 1.374\n",
      "[1,  8000] loss: 1.305\n",
      "[1, 10000] loss: 1.257\n",
      "[1, 12000] loss: 1.165\n",
      "Accuracy: 59.05 %\n",
      "\n",
      "Epoch: 2\n",
      "[2,  2000] loss: 1.089\n",
      "[2,  4000] loss: 1.069\n",
      "[2,  6000] loss: 1.050\n",
      "[2,  8000] loss: 1.025\n",
      "[2, 10000] loss: 1.021\n",
      "[2, 12000] loss: 1.019\n",
      "Accuracy: 66.01 %\n",
      "\n",
      "Epoch: 3\n",
      "[3,  2000] loss: 0.909\n",
      "[3,  4000] loss: 0.916\n",
      "[3,  6000] loss: 0.922\n",
      "[3,  8000] loss: 0.907\n",
      "[3, 10000] loss: 0.901\n",
      "[3, 12000] loss: 0.915\n",
      "Accuracy: 67.61 %\n",
      "\n",
      "Epoch: 4\n",
      "[4,  2000] loss: 0.815\n",
      "[4,  4000] loss: 0.841\n",
      "[4,  6000] loss: 0.822\n",
      "[4,  8000] loss: 0.855\n",
      "[4, 10000] loss: 0.859\n",
      "[4, 12000] loss: 0.861\n",
      "Accuracy: 67.31 %\n",
      "\n",
      "Epoch: 5\n",
      "[5,  2000] loss: 0.771\n",
      "[5,  4000] loss: 0.774\n",
      "[5,  6000] loss: 0.783\n",
      "[5,  8000] loss: 0.794\n",
      "[5, 10000] loss: 0.794\n",
      "[5, 12000] loss: 0.797\n",
      "Accuracy: 69.73 %\n",
      "\n",
      "Epoch: 6\n",
      "[6,  2000] loss: 0.680\n",
      "[6,  4000] loss: 0.736\n",
      "[6,  6000] loss: 0.724\n",
      "[6,  8000] loss: 0.768\n",
      "[6, 10000] loss: 0.765\n",
      "[6, 12000] loss: 0.775\n",
      "Accuracy: 69.26 %\n",
      "\n",
      "Epoch: 7\n",
      "[7,  2000] loss: 0.667\n",
      "[7,  4000] loss: 0.698\n",
      "[7,  6000] loss: 0.707\n",
      "[7,  8000] loss: 0.731\n",
      "[7, 10000] loss: 0.715\n",
      "[7, 12000] loss: 0.746\n",
      "Accuracy: 68.70 %\n",
      "\n",
      "Epoch: 8\n",
      "[8,  2000] loss: 0.637\n",
      "[8,  4000] loss: 0.681\n",
      "[8,  6000] loss: 0.689\n",
      "[8,  8000] loss: 0.687\n",
      "[8, 10000] loss: 0.699\n",
      "[8, 12000] loss: 0.696\n",
      "Accuracy: 68.08 %\n",
      "\n",
      "Epoch: 9\n",
      "[9,  2000] loss: 0.614\n",
      "[9,  4000] loss: 0.645\n",
      "[9,  6000] loss: 0.682\n",
      "[9,  8000] loss: 0.675\n",
      "[9, 10000] loss: 0.676\n",
      "[9, 12000] loss: 0.673\n",
      "Accuracy: 70.22 %\n",
      "\n",
      "Epoch: 10\n",
      "[10,  2000] loss: 0.606\n",
      "[10,  4000] loss: 0.618\n",
      "[10,  6000] loss: 0.633\n",
      "[10,  8000] loss: 0.661\n",
      "[10, 10000] loss: 0.670\n",
      "[10, 12000] loss: 0.664\n",
      "Accuracy: 68.45 %\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    print('Epoch:', (epoch+1))\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs, False, drop1=0, drop2=0, drop3=0, drop4=0, drop5=0)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    '''\n",
    "    # Save versions of the network\n",
    "    PATH = './cifar_net_qat' + str(epoch) + '.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "    '''\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0  \n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images, True, drop1=0, drop2=0, drop3=0, drop4=0, drop5=0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy: %.2f %%' % (100 * correct / float(total)))\n",
    "    \n",
    "    print(\"\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate and train with different dropouts range 0.1-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop rate 0.1\n",
      "\n",
      "Epoch: 1\n",
      "[1,  2000] loss: 2.271\n",
      "[1,  4000] loss: 2.012\n",
      "[1,  6000] loss: 1.761\n",
      "[1,  8000] loss: 1.603\n",
      "[1, 10000] loss: 1.517\n",
      "[1, 12000] loss: 1.446\n",
      "Accuracy: 49.41 %\n",
      "\n",
      "Epoch: 2\n",
      "[2,  2000] loss: 1.361\n",
      "[2,  4000] loss: 1.320\n",
      "[2,  6000] loss: 1.241\n",
      "[2,  8000] loss: 1.212\n",
      "[2, 10000] loss: 1.175\n",
      "[2, 12000] loss: 1.167\n",
      "Accuracy: 56.49 %\n",
      "\n",
      "Epoch: 3\n",
      "[3,  2000] loss: 1.100\n",
      "[3,  4000] loss: 1.060\n",
      "[3,  6000] loss: 1.070\n",
      "[3,  8000] loss: 1.063\n",
      "[3, 10000] loss: 1.032\n",
      "[3, 12000] loss: 1.013\n",
      "Accuracy: 65.42 %\n",
      "\n",
      "Epoch: 4\n",
      "[4,  2000] loss: 0.930\n",
      "[4,  4000] loss: 0.949\n",
      "[4,  6000] loss: 0.951\n",
      "[4,  8000] loss: 0.950\n",
      "[4, 10000] loss: 0.935\n",
      "[4, 12000] loss: 0.917\n",
      "Accuracy: 64.59 %\n",
      "\n",
      "Epoch: 5\n",
      "[5,  2000] loss: 0.854\n",
      "[5,  4000] loss: 0.837\n",
      "[5,  6000] loss: 0.852\n",
      "[5,  8000] loss: 0.869\n",
      "[5, 10000] loss: 0.853\n",
      "[5, 12000] loss: 0.853\n",
      "Accuracy: 66.68 %\n",
      "\n",
      "Epoch: 6\n",
      "[6,  2000] loss: 0.780\n",
      "[6,  4000] loss: 0.787\n",
      "[6,  6000] loss: 0.765\n",
      "[6,  8000] loss: 0.799\n",
      "[6, 10000] loss: 0.799\n",
      "[6, 12000] loss: 0.791\n",
      "Accuracy: 68.53 %\n",
      "\n",
      "Epoch: 7\n",
      "[7,  2000] loss: 0.690\n",
      "[7,  4000] loss: 0.734\n",
      "[7,  6000] loss: 0.727\n",
      "[7,  8000] loss: 0.737\n",
      "[7, 10000] loss: 0.742\n",
      "[7, 12000] loss: 0.771\n",
      "Accuracy: 70.16 %\n",
      "\n",
      "Epoch: 8\n",
      "[8,  2000] loss: 0.650\n",
      "[8,  4000] loss: 0.668\n",
      "[8,  6000] loss: 0.683\n",
      "[8,  8000] loss: 0.688\n",
      "[8, 10000] loss: 0.683\n",
      "[8, 12000] loss: 0.729\n",
      "Accuracy: 69.88 %\n",
      "\n",
      "Epoch: 9\n",
      "[9,  2000] loss: 0.617\n",
      "[9,  4000] loss: 0.633\n",
      "[9,  6000] loss: 0.643\n",
      "[9,  8000] loss: 0.652\n",
      "[9, 10000] loss: 0.653\n",
      "[9, 12000] loss: 0.664\n",
      "Accuracy: 69.53 %\n",
      "\n",
      "Epoch: 10\n",
      "[10,  2000] loss: 0.566\n",
      "[10,  4000] loss: 0.591\n",
      "[10,  6000] loss: 0.607\n",
      "[10,  8000] loss: 0.624\n",
      "[10, 10000] loss: 0.655\n",
      "[10, 12000] loss: 0.647\n",
      "Accuracy: 70.92 %\n",
      "\n",
      "Finished Training\n",
      "./cifar_drop_1.pth\n",
      "\n",
      "\n",
      "drop rate 0.2\n",
      "\n",
      "Epoch: 1\n",
      "[1,  2000] loss: 2.255\n",
      "[1,  4000] loss: 1.996\n",
      "[1,  6000] loss: 1.811\n",
      "[1,  8000] loss: 1.655\n",
      "[1, 10000] loss: 1.583\n",
      "[1, 12000] loss: 1.508\n",
      "Accuracy: 48.31 %\n",
      "\n",
      "Epoch: 2\n",
      "[2,  2000] loss: 1.410\n",
      "[2,  4000] loss: 1.361\n",
      "[2,  6000] loss: 1.326\n",
      "[2,  8000] loss: 1.298\n",
      "[2, 10000] loss: 1.254\n",
      "[2, 12000] loss: 1.234\n",
      "Accuracy: 55.96 %\n",
      "\n",
      "Epoch: 3\n",
      "[3,  2000] loss: 1.154\n",
      "[3,  4000] loss: 1.149\n",
      "[3,  6000] loss: 1.103\n",
      "[3,  8000] loss: 1.103\n",
      "[3, 10000] loss: 1.089\n",
      "[3, 12000] loss: 1.060\n",
      "Accuracy: 61.72 %\n",
      "\n",
      "Epoch: 4\n",
      "[4,  2000] loss: 1.002\n",
      "[4,  4000] loss: 0.984\n",
      "[4,  6000] loss: 0.991\n",
      "[4,  8000] loss: 0.987\n",
      "[4, 10000] loss: 0.997\n",
      "[4, 12000] loss: 0.994\n",
      "Accuracy: 64.56 %\n",
      "\n",
      "Epoch: 5\n",
      "[5,  2000] loss: 0.911\n",
      "[5,  4000] loss: 0.923\n",
      "[5,  6000] loss: 0.921\n",
      "[5,  8000] loss: 0.895\n",
      "[5, 10000] loss: 0.897\n",
      "[5, 12000] loss: 0.914\n",
      "Accuracy: 66.39 %\n",
      "\n",
      "Epoch: 6\n",
      "[6,  2000] loss: 0.840\n",
      "[6,  4000] loss: 0.842\n",
      "[6,  6000] loss: 0.852\n",
      "[6,  8000] loss: 0.843\n",
      "[6, 10000] loss: 0.866\n",
      "[6, 12000] loss: 0.856\n",
      "Accuracy: 67.03 %\n",
      "\n",
      "Epoch: 7\n",
      "[7,  2000] loss: 0.797\n",
      "[7,  4000] loss: 0.805\n",
      "[7,  6000] loss: 0.815\n",
      "[7,  8000] loss: 0.802\n",
      "[7, 10000] loss: 0.828\n",
      "[7, 12000] loss: 0.827\n",
      "Accuracy: 68.72 %\n",
      "\n",
      "Epoch: 8\n",
      "[8,  2000] loss: 0.748\n",
      "[8,  4000] loss: 0.759\n",
      "[8,  6000] loss: 0.782\n",
      "[8,  8000] loss: 0.779\n",
      "[8, 10000] loss: 0.780\n",
      "[8, 12000] loss: 0.770\n",
      "Accuracy: 69.11 %\n",
      "\n",
      "Epoch: 9\n",
      "[9,  2000] loss: 0.708\n",
      "[9,  4000] loss: 0.723\n",
      "[9,  6000] loss: 0.720\n",
      "[9,  8000] loss: 0.773\n",
      "[9, 10000] loss: 0.744\n",
      "[9, 12000] loss: 0.748\n",
      "Accuracy: 69.61 %\n",
      "\n",
      "Epoch: 10\n",
      "[10,  2000] loss: 0.689\n",
      "[10,  4000] loss: 0.701\n",
      "[10,  6000] loss: 0.708\n",
      "[10,  8000] loss: 0.722\n",
      "[10, 10000] loss: 0.721\n",
      "[10, 12000] loss: 0.750\n",
      "Accuracy: 70.59 %\n",
      "\n",
      "Finished Training\n",
      "./cifar_drop_2.pth\n",
      "\n",
      "\n",
      "drop rate 0.3\n",
      "\n",
      "Epoch: 1\n",
      "[1,  2000] loss: 2.285\n",
      "[1,  4000] loss: 2.046\n",
      "[1,  6000] loss: 1.912\n",
      "[1,  8000] loss: 1.770\n",
      "[1, 10000] loss: 1.680\n",
      "[1, 12000] loss: 1.606\n",
      "Accuracy: 44.99 %\n",
      "\n",
      "Epoch: 2\n",
      "[2,  2000] loss: 1.511\n",
      "[2,  4000] loss: 1.489\n",
      "[2,  6000] loss: 1.434\n",
      "[2,  8000] loss: 1.399\n",
      "[2, 10000] loss: 1.362\n",
      "[2, 12000] loss: 1.340\n",
      "Accuracy: 54.49 %\n",
      "\n",
      "Epoch: 3\n",
      "[3,  2000] loss: 1.290\n",
      "[3,  4000] loss: 1.258\n",
      "[3,  6000] loss: 1.251\n",
      "[3,  8000] loss: 1.198\n",
      "[3, 10000] loss: 1.211\n",
      "[3, 12000] loss: 1.182\n",
      "Accuracy: 58.54 %\n",
      "\n",
      "Epoch: 4\n",
      "[4,  2000] loss: 1.115\n",
      "[4,  4000] loss: 1.128\n",
      "[4,  6000] loss: 1.115\n",
      "[4,  8000] loss: 1.082\n",
      "[4, 10000] loss: 1.122\n",
      "[4, 12000] loss: 1.083\n",
      "Accuracy: 61.15 %\n",
      "\n",
      "Epoch: 5\n",
      "[5,  2000] loss: 1.027\n",
      "[5,  4000] loss: 1.024\n",
      "[5,  6000] loss: 1.014\n",
      "[5,  8000] loss: 1.025\n",
      "[5, 10000] loss: 1.016\n",
      "[5, 12000] loss: 1.026\n",
      "Accuracy: 62.50 %\n",
      "\n",
      "Epoch: 6\n",
      "[6,  2000] loss: 0.981\n",
      "[6,  4000] loss: 0.942\n",
      "[6,  6000] loss: 0.973\n",
      "[6,  8000] loss: 0.965\n",
      "[6, 10000] loss: 0.978\n",
      "[6, 12000] loss: 0.952\n",
      "Accuracy: 64.62 %\n",
      "\n",
      "Epoch: 7\n",
      "[7,  2000] loss: 0.898\n",
      "[7,  4000] loss: 0.926\n",
      "[7,  6000] loss: 0.928\n",
      "[7,  8000] loss: 0.925\n",
      "[7, 10000] loss: 0.934\n",
      "[7, 12000] loss: 0.901\n",
      "Accuracy: 65.74 %\n",
      "\n",
      "Epoch: 8\n",
      "[8,  2000] loss: 0.880\n",
      "[8,  4000] loss: 0.880\n",
      "[8,  6000] loss: 0.865\n",
      "[8,  8000] loss: 0.885\n",
      "[8, 10000] loss: 0.881\n",
      "[8, 12000] loss: 0.906\n",
      "Accuracy: 64.28 %\n",
      "\n",
      "Epoch: 9\n",
      "[9,  2000] loss: 0.853\n",
      "[9,  4000] loss: 0.850\n",
      "[9,  6000] loss: 0.851\n",
      "[9,  8000] loss: 0.842\n",
      "[9, 10000] loss: 0.852\n",
      "[9, 12000] loss: 0.879\n",
      "Accuracy: 68.14 %\n",
      "\n",
      "Epoch: 10\n",
      "[10,  2000] loss: 0.839\n",
      "[10,  4000] loss: 0.827\n",
      "[10,  6000] loss: 0.804\n",
      "[10,  8000] loss: 0.835\n",
      "[10, 10000] loss: 0.838\n",
      "[10, 12000] loss: 0.832\n",
      "Accuracy: 68.30 %\n",
      "\n",
      "Finished Training\n",
      "./cifar_drop_3.pth\n",
      "\n",
      "\n",
      "drop rate 0.4\n",
      "\n",
      "Epoch: 1\n",
      "[1,  2000] loss: 2.302\n",
      "[1,  4000] loss: 2.185\n",
      "[1,  6000] loss: 1.931\n",
      "[1,  8000] loss: 1.801\n",
      "[1, 10000] loss: 1.722\n",
      "[1, 12000] loss: 1.635\n",
      "Accuracy: 40.25 %\n",
      "\n",
      "Epoch: 2\n",
      "[2,  2000] loss: 1.548\n",
      "[2,  4000] loss: 1.511\n",
      "[2,  6000] loss: 1.496\n",
      "[2,  8000] loss: 1.455\n",
      "[2, 10000] loss: 1.429\n",
      "[2, 12000] loss: 1.381\n",
      "Accuracy: 50.47 %\n",
      "\n",
      "Epoch: 3\n",
      "[3,  2000] loss: 1.339\n",
      "[3,  4000] loss: 1.339\n",
      "[3,  6000] loss: 1.311\n",
      "[3,  8000] loss: 1.293\n",
      "[3, 10000] loss: 1.279\n",
      "[3, 12000] loss: 1.254\n",
      "Accuracy: 54.97 %\n",
      "\n",
      "Epoch: 4\n",
      "[4,  2000] loss: 1.215\n",
      "[4,  4000] loss: 1.199\n",
      "[4,  6000] loss: 1.192\n",
      "[4,  8000] loss: 1.187\n",
      "[4, 10000] loss: 1.198\n",
      "[4, 12000] loss: 1.166\n",
      "Accuracy: 58.30 %\n",
      "\n",
      "Epoch: 5\n",
      "[5,  2000] loss: 1.130\n",
      "[5,  4000] loss: 1.127\n",
      "[5,  6000] loss: 1.118\n",
      "[5,  8000] loss: 1.108\n",
      "[5, 10000] loss: 1.125\n",
      "[5, 12000] loss: 1.092\n",
      "Accuracy: 59.88 %\n",
      "\n",
      "Epoch: 6\n",
      "[6,  2000] loss: 1.056\n",
      "[6,  4000] loss: 1.077\n",
      "[6,  6000] loss: 1.038\n",
      "[6,  8000] loss: 1.073\n",
      "[6, 10000] loss: 1.080\n",
      "[6, 12000] loss: 1.069\n",
      "Accuracy: 61.75 %\n",
      "\n",
      "Epoch: 7\n",
      "[7,  2000] loss: 1.016\n",
      "[7,  4000] loss: 1.040\n",
      "[7,  6000] loss: 1.037\n",
      "[7,  8000] loss: 1.047\n",
      "[7, 10000] loss: 1.044\n",
      "[7, 12000] loss: 1.012\n",
      "Accuracy: 64.28 %\n",
      "\n",
      "Epoch: 8\n",
      "[8,  2000] loss: 0.983\n",
      "[8,  4000] loss: 1.000\n",
      "[8,  6000] loss: 0.996\n",
      "[8,  8000] loss: 1.010\n",
      "[8, 10000] loss: 1.020\n",
      "[8, 12000] loss: 1.007\n",
      "Accuracy: 64.57 %\n",
      "\n",
      "Epoch: 9\n",
      "[9,  2000] loss: 0.966\n",
      "[9,  4000] loss: 0.977\n",
      "[9,  6000] loss: 0.959\n",
      "[9,  8000] loss: 0.985\n",
      "[9, 10000] loss: 0.981\n",
      "[9, 12000] loss: 0.987\n",
      "Accuracy: 64.25 %\n",
      "\n",
      "Epoch: 10\n",
      "[10,  2000] loss: 0.962\n",
      "[10,  4000] loss: 0.939\n",
      "[10,  6000] loss: 0.951\n",
      "[10,  8000] loss: 0.958\n",
      "[10, 10000] loss: 0.974\n",
      "[10, 12000] loss: 0.977\n",
      "Accuracy: 63.92 %\n",
      "\n",
      "Finished Training\n",
      "./cifar_drop_4.pth\n",
      "\n",
      "\n",
      "drop rate 0.5\n",
      "\n",
      "Epoch: 1\n",
      "[1,  2000] loss: 2.291\n",
      "[1,  4000] loss: 2.146\n",
      "[1,  6000] loss: 1.960\n",
      "[1,  8000] loss: 1.824\n",
      "[1, 10000] loss: 1.753\n",
      "[1, 12000] loss: 1.698\n",
      "Accuracy: 38.14 %\n",
      "\n",
      "Epoch: 2\n",
      "[2,  2000] loss: 1.628\n",
      "[2,  4000] loss: 1.597\n",
      "[2,  6000] loss: 1.548\n",
      "[2,  8000] loss: 1.529\n",
      "[2, 10000] loss: 1.512\n",
      "[2, 12000] loss: 1.477\n",
      "Accuracy: 47.93 %\n",
      "\n",
      "Epoch: 3\n",
      "[3,  2000] loss: 1.436\n",
      "[3,  4000] loss: 1.416\n",
      "[3,  6000] loss: 1.397\n",
      "[3,  8000] loss: 1.379\n",
      "[3, 10000] loss: 1.364\n",
      "[3, 12000] loss: 1.349\n",
      "Accuracy: 52.56 %\n",
      "\n",
      "Epoch: 4\n",
      "[4,  2000] loss: 1.315\n",
      "[4,  4000] loss: 1.296\n",
      "[4,  6000] loss: 1.318\n",
      "[4,  8000] loss: 1.278\n",
      "[4, 10000] loss: 1.286\n",
      "[4, 12000] loss: 1.262\n",
      "Accuracy: 55.87 %\n",
      "\n",
      "Epoch: 5\n",
      "[5,  2000] loss: 1.237\n",
      "[5,  4000] loss: 1.236\n",
      "[5,  6000] loss: 1.237\n",
      "[5,  8000] loss: 1.218\n",
      "[5, 10000] loss: 1.209\n",
      "[5, 12000] loss: 1.219\n",
      "Accuracy: 57.82 %\n",
      "\n",
      "Epoch: 6\n",
      "[6,  2000] loss: 1.192\n",
      "[6,  4000] loss: 1.213\n",
      "[6,  6000] loss: 1.164\n",
      "[6,  8000] loss: 1.189\n",
      "[6, 10000] loss: 1.158\n",
      "[6, 12000] loss: 1.201\n",
      "Accuracy: 56.19 %\n",
      "\n",
      "Epoch: 7\n",
      "[7,  2000] loss: 1.157\n",
      "[7,  4000] loss: 1.159\n",
      "[7,  6000] loss: 1.147\n",
      "[7,  8000] loss: 1.141\n",
      "[7, 10000] loss: 1.131\n",
      "[7, 12000] loss: 1.166\n",
      "Accuracy: 58.53 %\n",
      "\n",
      "Epoch: 8\n",
      "[8,  2000] loss: 1.122\n",
      "[8,  4000] loss: 1.116\n",
      "[8,  6000] loss: 1.131\n",
      "[8,  8000] loss: 1.122\n",
      "[8, 10000] loss: 1.125\n",
      "[8, 12000] loss: 1.126\n",
      "Accuracy: 60.13 %\n",
      "\n",
      "Epoch: 9\n",
      "[9,  2000] loss: 1.091\n",
      "[9,  4000] loss: 1.101\n",
      "[9,  6000] loss: 1.111\n",
      "[9,  8000] loss: 1.110\n",
      "[9, 10000] loss: 1.088\n",
      "[9, 12000] loss: 1.123\n",
      "Accuracy: 59.39 %\n",
      "\n",
      "Epoch: 10\n",
      "[10,  2000] loss: 1.072\n",
      "[10,  4000] loss: 1.070\n",
      "[10,  6000] loss: 1.094\n",
      "[10,  8000] loss: 1.093\n",
      "[10, 10000] loss: 1.071\n",
      "[10, 12000] loss: 1.102\n",
      "Accuracy: 61.65 %\n",
      "\n",
      "Finished Training\n",
      "./cifar_drop_5.pth\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over dropout over range\n",
    "drop_r = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "text = ['1', '2', '3', '4', '5']\n",
    "\n",
    "for j in range(len(drop_r)):\n",
    "    print(\"drop rate\", drop_r[j])\n",
    "    print(\"\")\n",
    "    net = Net(train_drop1=0, train_drop2=0, train_drop3=drop_r[j], train_drop4=drop_r[j], train_drop5=drop_r[j])\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "        print('Epoch:', (epoch+1))\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs, False, drop1=0, drop2=0, drop3=0, drop4=0, drop5=0)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        correct = 0\n",
    "        total = 0  \n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                outputs = net(images, True, drop1=0, drop2=0, drop3=0, drop4=0, drop5=0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        print('Accuracy: %.2f %%' % (100 * correct / float(total)))\n",
    "\n",
    "        print(\"\")\n",
    "\n",
    "    print('Finished Training')\n",
    "    \n",
    "    PATH = './cifar_drop_' + text[j] + '.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "    print(PATH)\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with some dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHS = ['./sample_models/cifar_weight_2_1e-3.pth', './sample_models/cifar_weight_2_5e-3.pth', './sample_models/cifar_net_sgd_72_41.pth']\n",
    "drops = [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6]\n",
    "\n",
    "for i in range(len(PATHS)):\n",
    "    print(PATHS[i])\n",
    "    net = Net(train_drop1=0, train_drop2=0, train_drop3=0, train_drop4=0, train_drop5=0)\n",
    "    net.load_state_dict(torch.load(PATHS[i]))\n",
    "\n",
    "    for j in range(len(drops)):\n",
    "        correct = 0\n",
    "        total = 0 \n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                outputs = net(images, True, drop1=0, drop2=0, drop3=drops[j], drop4=drops[j], drop5=drops[j])\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        print('Drop:', drops[j], 'Accuracy: %.2f %%' % (100 * correct / float(total)))\n",
    "                \n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
